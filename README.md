# Agostino Cardamone

👨‍💻 **Student** in **Computer Engineering** specializing in **Artificial Intelligence** at the **University of Salerno**.  
🚗 Passionate about **automotive technologies** and **robotics**, with a strong focus on developing AI solutions for **autonomous systems**.

---

## 🔧 Technical Skills
- 🧠 **Machine Learning & AI**: PyTorch, TensorFlow, OpenCV, RASA
- 🔍 **Computer Vision**: YOLO, OpenCV
- 🏎️ **Autonomous Vehicles**: ROS, Carla Simulator
- 💻 **Software Development**: Python, C, C#, Java, HTML, CSS, PHP
- 🔌 **Embedded Systems**: STM32

---

## 📌 Featured Projects

### 🤖 **Guardian of the Aisles: AI-Powered Shopping Assistant**
An AI-driven robotic assistant designed for shopping malls, with **Pepper** as the interactive guide and security assistant. The system leverages **video analysis, speech recognition**, and a **modular ROS architecture** to improve customer experience.

#### Key Features:
- ✅ **Real-Time Video Analysis** – Person detection and attribute recognition (e.g., gender, accessories)
- ✅ **Voice Interaction** – Support for **Speech-to-Text (S2T)** and **Text-to-Speech (TTS)**
- ✅ **Chatbot Integration** – Provides answers to questions about stores and events, including the **Artificial Vision Contest 2025**
- ✅ **ROS Architecture** – Flexible, scalable, and efficient
- ✅ **Multi-Hardware Support** – Uses **Pepper's camera** and **external cameras**
- ✅ **Interactive Animations** – Syncs voice with gestures for natural interaction

🔗 [GitHub Repository](https://github.com/Crostino14/Cognitive-Robotics-Group-4)

### 🏆 **Artificial Vision Contest 2025 – AI-Powered Video Analysis**
A project developed for the **Artificial Vision Contest 2025**, focusing on **detecting, tracking, and analyzing human behavior in videos**.

#### Project Goals:
- ✅ **Person Detection** in videos
- ✅ **Tracking Movements** over time
- ✅ **Attribute Classification** (gender, presence of bag and hat)
- ✅ **Behavior Analysis and Virtual Line Crossings**

#### How It Works:
1. Processes an **input video** and a **configuration file** with virtual lines.
2. Detects and tracks people, extracting **attributes and trajectories**.
3. Generates a **results file** with tracking and behavior data.
4. Compares the results with **ground truth** to evaluate performance.

🔗 [GitHub Repository](https://github.com/Crostino14/Artificial-Vision-Group-4)

---

## 📫 Contact

🌐 **LinkedIn**: [linkedin.com/in/agostinocardamone](https://linkedin.com/in/agostinocardamone)
