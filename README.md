# 🚀 Agostino Cardamone

### 👨‍💻 Artificial Intelligence & Autonomous Vehicles Enthusiast

🎓 Sono uno studente di **Ingegneria Informatica** specializzato in **Intelligenza Artificiale** presso l'Università degli Studi di Salerno.  
🚗 Appassionato di **automotive** e **robotica**.  

---

## 🔧 Competenze Tecniche
- 🧠 **Machine Learning & AI**: PyTorch, TensorFlow, OpenCV, RASA
- 🔍 **Computer Vision**: YOLO, OpenCV
- 🏎️ **Autonomous Vehicles**: ROS, Carla Simulator
- 💻 **Sviluppo Software**: Python, C, C#, Java, HTML, CSS, PHP
- 🔌 **Embedded Systems**: STM32

---

## 📌 Progetti Principali

### 🤖 Guardian of the Aisles: AI-Powered Shopping Assistant  
🏬 **Descrizione**  
Un assistente robotico basato su AI per i centri commerciali, con **Pepper** come guida interattiva e assistente di sicurezza.  
Il sistema sfrutta **analisi video, riconoscimento vocale** e un'**architettura ROS modulare** per migliorare l'esperienza dei clienti.

🔹 **Caratteristiche**  
✅ **Analisi Video in Tempo Reale** – Rilevamento di persone e riconoscimento attributi (genere, accessori, ecc.)  
✅ **Interazione Vocale** – Supporto per **Speech-to-Text (S2T)** e **Text-to-Speech (TTS)**  
✅ **Integrazione con Chatbot** – Risponde a domande sui negozi e sull'evento **Artificial Vision Contest 2025**  
✅ **Architettura ROS** – Flessibile, scalabile ed efficiente  
✅ **Hardware Multiplo** – Supporto per la **fotocamera di Pepper** e **telecamere esterne**  
✅ **Animazioni Interattive** – Sincronizzazione tra voce e gesti per un'interazione più naturale  

🔗 **Repository GitHub**: [Link al progetto]((https://github.com/Crostino14/Cognitive-Robotics-Group-4))

### 🏆 Artificial Vision Contest 2025 – AI-Powered Video Analysis  
🔍 **Descrizione**  
Progetto sviluppato per il **Artificial Vision Contest 2025**, una competizione in cui i team devono creare una soluzione software avanzata per il **rilevamento, tracciamento e analisi del comportamento umano nei video**.

📌 **Obiettivi del Progetto**  
✅ **Rilevamento delle persone** nei video  
✅ **Tracciamento dei movimenti** nel tempo  
✅ **Classificazione degli attributi** (genere, presenza di borsa e cappello)  
✅ **Analisi del comportamento e attraversamenti** di linee virtuali  

⚙️ **Come Funziona?**  
1. Il sistema elabora un **video di input** e un **file di configurazione** con le linee virtuali.  
2. Identifica e traccia le persone, estraendo **attributi e traiettorie**.  
3. Genera un **file di risultati** con i dati di tracking e comportamento.  
4. I risultati vengono confrontati con il **ground truth** per determinare il punteggio di performance.

🔗 **Repository GitHub**: [Link al progetto]((https://github.com/Crostino14/Artificial-Vision-Group-4))

---

## 📫 Contatti
🌐 **LinkedIn**: [linkedin.com/in/agostinocardamone](https://linkedin.com/in/agostinocardamone)  
