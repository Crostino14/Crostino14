# Agostino Cardamone

ğŸ‘¨â€ğŸ’» **Student** in **Computer Engineering** specializing in **Artificial Intelligence** at the **University of Salerno**.  
ğŸš— Passionate about **automotive technologies** and **robotics**, with a strong focus on developing AI solutions for **autonomous systems**.

---

## ğŸ”§ Technical Skills
- ğŸ§  **Machine Learning & AI**: PyTorch, TensorFlow, OpenCV, RASA
- ğŸ” **Computer Vision**: YOLO, OpenCV
- ğŸï¸ **Autonomous Vehicles**: ROS, Carla Simulator
- ğŸ’» **Software Development**: Python, C, C#, Java, HTML, CSS, PHP
- ğŸ”Œ **Embedded Systems**: STM32

---

## ğŸ“Œ Featured Projects

### ğŸ¤– **Guardian of the Aisles: AI-Powered Shopping Assistant**
An AI-driven robotic assistant designed for shopping malls, with **Pepper** as the interactive guide and security assistant. The system leverages **video analysis, speech recognition**, and a **modular ROS architecture** to improve customer experience.

#### Key Features:
- âœ… **Real-Time Video Analysis** â€“ Person detection and attribute recognition (e.g., gender, accessories)
- âœ… **Voice Interaction** â€“ Support for **Speech-to-Text (S2T)** and **Text-to-Speech (TTS)**
- âœ… **Chatbot Integration** â€“ Provides answers to questions about stores and events, including the **Artificial Vision Contest 2025**
- âœ… **ROS Architecture** â€“ Flexible, scalable, and efficient
- âœ… **Multi-Hardware Support** â€“ Uses **Pepper's camera** and **external cameras**
- âœ… **Interactive Animations** â€“ Syncs voice with gestures for natural interaction

ğŸ”— [GitHub Repository](https://github.com/Crostino14/Cognitive-Robotics-Group-4)

### ğŸ† **Artificial Vision Contest 2025 â€“ AI-Powered Video Analysis**
A project developed for the **Artificial Vision Contest 2025**, focusing on **detecting, tracking, and analyzing human behavior in videos**.

#### Project Goals:
- âœ… **Person Detection** in videos
- âœ… **Tracking Movements** over time
- âœ… **Attribute Classification** (gender, presence of bag and hat)
- âœ… **Behavior Analysis and Virtual Line Crossings**

#### How It Works:
1. Processes an **input video** and a **configuration file** with virtual lines.
2. Detects and tracks people, extracting **attributes and trajectories**.
3. Generates a **results file** with tracking and behavior data.
4. Compares the results with **ground truth** to evaluate performance.

ğŸ”— [GitHub Repository](https://github.com/Crostino14/Artificial-Vision-Group-4)

---

## ğŸ“« Contact

ğŸŒ **LinkedIn**: [linkedin.com/in/agostinocardamone](https://linkedin.com/in/agostinocardamone)
